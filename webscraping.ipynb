{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "## Webscraping\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib2 as ul\n",
    "import sys, os, math, shutil\n",
    "import zipfile\n",
    "import re\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "## PostGres DB\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext sql\n",
    "%config SqlMagic.autopandas=True\n",
    "\n",
    "## Python 3-like\n",
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ------------------------------------\n",
    "def get_npages(soup):\n",
    "    \"\"\"\n",
    "    Retrieves the total number of pages to crawl\n",
    "    for a particular letter on dafont\n",
    "    \"\"\"\n",
    "    \n",
    "    n = 0\n",
    "    \n",
    "    ## Locate all links in the file\n",
    "    for link in soup.find_all('a'):\n",
    "        \n",
    "        ## Retrive link text\n",
    "        link_text = link.get('href')\n",
    "        \n",
    "        if link_text is None: continue\n",
    "        \n",
    "        ## Look only for the links that refer to other dafont pages\n",
    "        if 'alpha.php' in link_text:\n",
    "            try:\n",
    "                ## Retrieve the last number of the link, corresponding to the page number\n",
    "                current_n = int(re.findall(r'\\d+', link_text)[-1])\n",
    "            except IndexError:\n",
    "                current_n = 0\n",
    "            if current_n > n:\n",
    "                n = current_n\n",
    "                \n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Specify the headers necessary to read the dafont.com pages\n",
    "USERAGENT = 'something'\n",
    "HEADERS = {'User-Agent': USERAGENT}\n",
    "\n",
    "## Specify the URL pattern for dafont.com pages\n",
    "dafont_pattern = 'http://www.dafont.com/alpha.php?lettre={0}&page={1}'\n",
    "\n",
    "## --------------------------------------\n",
    "def get_dafont_page_soup(lettre, i):\n",
    "    \"\"\"\n",
    "    Returns the soup for a particular dafont page\n",
    "    \"\"\"\n",
    "    \n",
    "    request = ul.Request(dafont_pattern.format(lettre, i), headers=HEADERS)\n",
    "    response = ul.urlopen(request)\n",
    "    soup = BeautifulSoup(response, 'lxml')\n",
    "    response.close()\n",
    "    \n",
    "    return soup\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## --------------------------------------\n",
    "def unicode_bullshit(text):\n",
    "    \"\"\"\n",
    "    Deals with weird encodings\n",
    "    \"\"\"\n",
    "    return ''.join([c if ord(c) < 128 else '_' for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FontInfo(object):\n",
    "    \"\"\"\n",
    "    A class to store the info scrapped from dafont\n",
    "    about a particular font\n",
    "    \"\"\"\n",
    "    \n",
    "    font_exts = ['otf', 'ttf']\n",
    "    \n",
    "    ## ----------------------------------------\n",
    "    def __init__(self, name, url, licensing, download_link, timestamp):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "\n",
    "        self.name = unicode_bullshit(name)\n",
    "        self.url  = unicode_bullshit(url)\n",
    "        self.licensing = unicode_bullshit(licensing)\n",
    "        self.download_link = unicode_bullshit(download_link)\n",
    "        self.timestamp = timestamp\n",
    "        self.paths = []\n",
    "        \n",
    "        \n",
    "    ## ----------------------------------------\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        string representation for print method\n",
    "        \"\"\"\n",
    "        \n",
    "        return \"\"\"\n",
    "        {0}\n",
    "        URL : {1}\n",
    "        {2}\n",
    "        download : {3}\n",
    "        \"\"\".format(\n",
    "            self.name,\n",
    "            self.url,\n",
    "            self.licensing,\n",
    "            self.download_link\n",
    "        )\n",
    "    \n",
    "    \n",
    "    ## ----------------------------------------\n",
    "    def download(self, path):\n",
    "        \"\"\"\n",
    "        Download the font\n",
    "        \"\"\"\n",
    "        \n",
    "        ## Remember where we're from\n",
    "        cwd = os.getcwd()\n",
    "        \n",
    "        ## Create the destination directory\n",
    "        try:\n",
    "            os.mkdir(path)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        ## Create a temporary directory\n",
    "        tmp_path = os.path.join(path,'tmp')\n",
    "        \n",
    "        try:\n",
    "            os.mkdir(tmp_path)\n",
    "        except:\n",
    "            shutil.rmtree(tmp_path)\n",
    "            os.mkdir(tmp_path)\n",
    "        \n",
    "        os.chdir(tmp_path)\n",
    "        \n",
    "        ## download file name, assuming it's a zip file first\n",
    "        fname = self.download_link.split('=')[-1] + '.zip'\n",
    "        \n",
    "        ## Download the file\n",
    "        data = ul.urlopen(self.download_link)\n",
    "        \n",
    "        ## Save the file to disk\n",
    "        with open(fname, 'wb') as f:\n",
    "            f.write(data.read())\n",
    "            f.close()\n",
    "            \n",
    "        ## open the zip file\n",
    "        try:\n",
    "            zf = zipfile.ZipFile(fname, 'r')\n",
    "        except zipfile.BadZipfile:\n",
    "            os.chdir(cwd)\n",
    "            return False\n",
    "        \n",
    "        for f in zf.namelist():\n",
    "            ext = f.split('.')[-1].lower()\n",
    "            if not ext in self.font_exts: continue\n",
    "            \n",
    "            try:\n",
    "                zf.extract(f)\n",
    "            except:\n",
    "                os.chdir(cwd)\n",
    "                return False\n",
    "            \n",
    "            ## Remove directory structure\n",
    "            if os.pathsep in f:\n",
    "                shutil.move(f, os.path.split(f)[-1])\n",
    "            \n",
    "            new_path = os.path.join(path, os.path.split(f)[-1])\n",
    "            new_path = unicode_bullshit(new_path)\n",
    "            shutil.move(os.path.join(tmp_path, f), new_path)\n",
    "            self.paths.append(new_path)\n",
    "            \n",
    "        if not self.paths:\n",
    "            os.chdir(cwd)\n",
    "            return False\n",
    "            \n",
    "        os.chdir(cwd)\n",
    "        return True\n",
    "        \n",
    "             \n",
    "\n",
    "\n",
    "## ----------------------------------------\n",
    "def get_font_infos(soup):\n",
    "    \"\"\"\n",
    "    Returns a list of FontInfo objects from a dafont page \n",
    "    \"\"\"\n",
    "    \n",
    "    font_infos = []\n",
    "    \n",
    "    html_names = soup.find_all('div', class_='lv1left dfbg')\n",
    "    html_infos = soup.find_all('div', class_='lv2right')\n",
    "    html_dnlds = soup.find_all('div', class_='dlbox')\n",
    "    \n",
    "    for html_name, html_info, html_dnld in zip(html_names, html_infos, html_dnlds):\n",
    "        name      = html_name.a.get_text()\n",
    "        href      = html_name.a.get('href')\n",
    "        \n",
    "        try:\n",
    "            licensing = html_info.find_all('a', class_='tdn help black')[0].get_text()\n",
    "        except:\n",
    "            licensing = 'Unknown'\n",
    "            \n",
    "        dl_link = html_dnld.a.get('href')\n",
    "        \n",
    "        url = 'http://www.dafont.com/{0}'.format(href)\n",
    "        \n",
    "        ## Go get the date\n",
    "        request = ul.Request(url, headers=HEADERS)\n",
    "        response = ul.urlopen(request)\n",
    "        date_soup = BeautifulSoup(response, 'lxml')\n",
    "        response.close()\n",
    "        \n",
    "        timestamp = 0.0\n",
    "        \n",
    "        potential_dates = date_soup.find_all('div', class_='dfsmall')\n",
    "        for potential_date in potential_dates:\n",
    "            text = potential_date.get_text()\n",
    "            if 'First seen on DaFont' in text:\n",
    "                text = text.split(':')[1].split('-')[0]\n",
    "                if 'before' in text.lower():\n",
    "                    break\n",
    "                else:\n",
    "                    dt = parse(text)\n",
    "                    timestamp = (dt - datetime.datetime(2004,1,1)).total_seconds()\n",
    "                    break\n",
    "                    \n",
    "        font_infos.append(FontInfo(name, url, licensing, dl_link, timestamp))\n",
    "        \n",
    "    return font_infos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://emitc2h:8PhHrB4wvVPJfjr@fontdbinstance.c9mwqfkzqqmh.us-west-2.rds.amazonaws.com:5432/fontdb\n"
     ]
    }
   ],
   "source": [
    "## Connect to the DB\n",
    "dbname = 'fontdb'\n",
    "username = 'emitc2h'\n",
    "pswd = '8PhHrB4wvVPJfjr'\n",
    "\n",
    "database_address = 'postgresql://{0}:{1}@fontdbinstance.c9mwqfkzqqmh.us-west-2.rds.amazonaws.com:5432/{2}'.format(username,pswd,dbname)\n",
    "if not database_exists(database_address):\n",
    "    create_database(database_address)\n",
    "\n",
    "engine = create_engine(database_address)\n",
    "print(engine.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Different possible lettres for the dafont urls\n",
    "lettres = [\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q',\n",
    "    'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '%23'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter a, ~1860 fonts ...\n",
      "Now downloading fonts for letter 'a', page 1/93 ...\n",
      "Now downloading fonts for letter 'a', page 2/93 ...\n"
     ]
    }
   ],
   "source": [
    "import boto\n",
    "from boto.s3.key import Key\n",
    "s3 = boto.connect_s3()\n",
    "bucket = s3.get_bucket('fontfinder-fontfiles', validate=False)\n",
    "\n",
    "for lettre in lettres:\n",
    "    \n",
    "    soup = get_dafont_page_soup(lettre, 1)\n",
    "    n_pages = get_npages(soup)\n",
    "    \n",
    "    print ('Letter {0}, ~{1} fonts ...'.format(lettre, n_pages*20))\n",
    "    \n",
    "    for i in range(1, n_pages+1):\n",
    "        \n",
    "        ## Don't start from the beginning every time\n",
    "        #if lettre in  ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q']: continue\n",
    "        #if lettre == 'r' and i < 17: continue\n",
    "        \n",
    "        print(\"Now downloading fonts for letter '{0}', page {1}/{2} ...\".format(lettre, i, n_pages))\n",
    "    \n",
    "        soup = get_dafont_page_soup(lettre, i)\n",
    "        font_infos = get_font_infos(soup)\n",
    "    \n",
    "        names          = []\n",
    "        urls           = []\n",
    "        licensings     = []\n",
    "        download_links = []\n",
    "        origins        = []\n",
    "        timestamps     = []\n",
    "        aws_bucket     = []\n",
    "        aws_bucket_key = []\n",
    "    \n",
    "        for font_info in font_infos:\n",
    "            #print(font_info)\n",
    "            if not font_info.download('/Users/mtm/Projects/FontFinder/dafont_fonts2'): continue\n",
    "                \n",
    "            for font_path in font_info.paths:\n",
    "        \n",
    "                font_file_name = os.path.split(font_path)[-1]\n",
    "                aws_key        = 'dafont_fonts/{0}'.format(font_file_name).replace(' ', '_')\n",
    "                \n",
    "                k = Key(bucket)\n",
    "                k.key = aws_key\n",
    "                k.set_contents_from_filename(font_path)\n",
    "        \n",
    "                names.append(font_info.name)\n",
    "                urls.append(font_info.url)\n",
    "                licensings.append(font_info.licensing)\n",
    "                download_links.append(font_info.download_link)\n",
    "                timestamps.append(font_info.timestamp)\n",
    "                origins.append('dafont.com')\n",
    "                aws_bucket.append('fontfinder-fontfiles')\n",
    "                aws_bucket_key.append(aws_key)\n",
    "                \n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                'name'           : names,\n",
    "                'url'            : urls,\n",
    "                'licensing'      : licensings,\n",
    "                'download_link'  : download_links,\n",
    "                'aws_bucket'     : aws_bucket,\n",
    "                'aws_bucket_key' : aws_bucket_key,\n",
    "                'origin'         : origins,\n",
    "                'timestamp'      : timestamps\n",
    "            }\n",
    "        )\n",
    "    \n",
    "        df.to_sql('font_metadata', engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%sql postgresql://emitc2h:8PhHrB4wvVPJfjr@fontdbinstance.c9mwqfkzqqmh.us-west-2.rds.amazonaws.com:5432/fontdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_font_metadata = %sql SELECT * FROM font_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_font_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql DROP TABLE font_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
